import streamlit as st
from huggingface_hub import InferenceClient
import re

# âœ… ì‚¬ìš©ì ì…ë ¥ í•„í„°ë§ í•¨ìˆ˜
def clean_input(text):
    text = re.sub(r"\b(í•´ì¤˜|ì•Œë ¤ì¤˜|ì„¤ëª…í•´ ì¤˜|ë§í•´ ì¤˜)\b", "", text, flags=re.IGNORECASE)
    return text.strip()

# âœ… ì§€ì§„ ê´€ë ¨ ì§ˆë¬¸ í•„í„°ë§ í•¨ìˆ˜
def is_earthquake_related(text):
    earthquake_keywords = ["ì§€ì§„", "ì§„ë„", "ì§„ì•™", "ì§€ì§„ ëŒ€ë¹„", "ì“°ë‚˜ë¯¸", "ëŒ€í”¼ì†Œ"]
    return any(keyword in text for keyword in earthquake_keywords)

# âœ… Hugging Face API í† í° ê°€ì ¸ì˜¤ê¸°
def get_huggingface_token():
    return st.secrets.get("HUGGINGFACE_API_TOKEN")

# âœ… AI ì±—ë´‡ ì‹¤í–‰ í•¨ìˆ˜
def run_sangdam():
    st.markdown("<h1 style='text-align: center; color: #007bff;'>ğŸŒ ì§€ì§„ ëŒ€ë¹„ AI ì±—ë´‡</h1>", unsafe_allow_html=True)

    # âœ… ì‚¬ìš© ë°©ë²• ì•ˆë‚´
    st.info(
        """
        ğŸ” **ì´ ì±—ë´‡ì€ ë‹¤ìŒ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.**  
        - âœ… ì‹¤ì‹œê°„ ì§€ì§„ ëŒ€ë¹„ ë° ì•ˆì „ ëŒ€ì±… ì œê³µ  
        - âœ… ì§€ì§„ ë°œìƒ ì‹œ í–‰ë™ ìš”ë ¹ ì•ˆë‚´  
        - âœ… ë‚´ì§„ ì„¤ê³„ ë° ì§€ì§„ ì˜ˆì¸¡ ê´€ë ¨ ì •ë³´ ì œê³µ  
        - âœ… ì“°ë‚˜ë¯¸ ë° ê¸´ê¸‰ ëŒ€í”¼ì†Œ ì •ë³´ ì•ˆë‚´  

        **ğŸ“ ì‚¬ìš© ë°©ë²•:**  
        1ï¸âƒ£ ì•„ë˜ ì…ë ¥ì°½ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.  
        2ï¸âƒ£ AIê°€ ì§€ì§„ ëŒ€ë¹„ ê´€ë ¨ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.  
        3ï¸âƒ£ ì›í•˜ëŠ” ì§ˆë¬¸ì„ ë°˜ë³µ ì…ë ¥í•˜ì—¬ ìƒë‹´í•˜ì„¸ìš”.  
        """
    )

    # âœ… ì˜ˆì‹œ ì§ˆë¬¸ í‘œì‹œ
    with st.expander("ğŸ’¡ ì˜ˆì‹œ ì§ˆë¬¸ ë³´ê¸°"):
        st.markdown(
            """
            - "ìµœê·¼ ì§€ì§„ ì •ë³´ëŠ” ì–´ë””ì„œ í™•ì¸í•  ìˆ˜ ìˆë‚˜ìš”?"  
            - "ì§€ì§„ ë°œìƒ ì‹œ ê°€ì¥ ì•ˆì „í•œ ì¥ì†ŒëŠ”?"  
            - "ì§€ì§„ ëŒ€ë¹„ë¥¼ ìœ„í•´ ì–´ë–¤ ë¬¼í’ˆì„ ì¤€ë¹„í•´ì•¼ í•˜ë‚˜ìš”?"  
            - "ë‚´ì§„ ì„¤ê³„ê°€ ì¤‘ìš”í•œ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"  
            - "ì“°ë‚˜ë¯¸ ê²½ë³´ê°€ ë°œë ¹ë˜ë©´ ì–´ë–»ê²Œ ëŒ€ì²˜í•´ì•¼ í•˜ë‚˜ìš”?"  
            """,
            unsafe_allow_html=True
        )

    token = get_huggingface_token()
    client = InferenceClient(model="google/gemma-2-9b-it", api_key=token)

    # âœ… ê¸°ì¡´ ì±„íŒ… ê¸°ë¡ ìœ ì§€
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ì§€ì§„ ëŒ€ë¹„ ì±—ë´‡ì…ë‹ˆë‹¤. ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”!"}
        ]

    # âœ… ê¸°ì¡´ ì±„íŒ… ê¸°ë¡ í‘œì‹œ
    for message in st.session_state.messages:
        role = "ğŸ‘¤ ì‚¬ìš©ì" if message["role"] == "user" else "ğŸ¤– AI"
        with st.chat_message(role):
            st.markdown(message["content"])

    # âœ… ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
    chat = st.chat_input("ì§€ì§„ ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”!")

    if chat:
        clean_chat = clean_input(chat)

        if not is_earthquake_related(clean_chat):
            response = "âŒ ì£„ì†¡í•©ë‹ˆë‹¤. ì§€ì§„ ê´€ë ¨ ìƒë‹´ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤."
        else:
            # âœ… AI ì‘ë‹µ ìš”ì²­ (Gemma ëª¨ë¸ ì‚¬ìš©)
            system_prompt = (
                "ë„ˆëŠ” ì§€ì§„ ëŒ€ë¹„ ë° ìì—°ì¬í•´ ì „ë¬¸ê°€ AIì•¼. "
                "ì§€ì§„ ê´€ë ¨ ì§ˆë¬¸ì— ëŒ€í•´ì„œë§Œ ëŒ€ë‹µí•˜ê³ , ë‹¤ë¥¸ ì§ˆë¬¸ì€ ì •ì¤‘íˆ ê±°ì ˆí•´."
            )
            full_prompt = system_prompt + "\n\n" + clean_chat

            response = client.text_generation(prompt=full_prompt, max_new_tokens=520)

        # âœ… ì±„íŒ… ê¸°ë¡ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": clean_chat})
        st.session_state.messages.append({"role": "assistant", "content": response})

        # âœ… AI ì‘ë‹µ í‘œì‹œ
        with st.chat_message("ğŸ‘¤ ì‚¬ìš©ì"):
            st.markdown(clean_chat)

        with st.chat_message("ğŸ¤– AI"):
            st.markdown(response)
